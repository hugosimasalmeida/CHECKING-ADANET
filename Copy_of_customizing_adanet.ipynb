{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of customizing_adanet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "qdOigM89PNgi",
        "colab_type": "code",
        "outputId": "4ffaa16a-891c-404e-d111-abdb93870b1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 14300
        }
      },
      "cell_type": "code",
      "source": [
        "# Install bazel\n",
        "!wget https://github.com/bazelbuild/bazel/releases/download/0.19.0/bazel-0.19.0-installer-linux-x86_64.sh \\\n",
        "  && chmod +x bazel-0.19.0-installer-linux-x86_64.sh \\\n",
        "  && ./bazel-0.19.0-installer-linux-x86_64.sh --user \\\n",
        "  && ln -sf $HOME/bin/bazel /usr/local/bin/bazel\n",
        "\n",
        "# Install AdaNet\n",
        "!git clone https://github.com/tensorflow/adanet \\\n",
        "  && cd adanet \\\n",
        "  && bazel build //adanet/pip_package:build_pip_package \\\n",
        "  && bazel-bin/adanet/pip_package/build_pip_package /tmp/adanet_pkg \\\n",
        "  && pip install /tmp/adanet_pkg/*.whl \\\n",
        "  && cd ~ \\\n",
        "  && python -c \"import adanet\"\n",
        "\n",
        "# from adanet.examples import simple_dnn is not working.\n",
        "%run /content/adanet/adanet/examples/simple_dnn.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-10-31 18:41:58--  https://github.com/bazelbuild/bazel/releases/download/0.19.0/bazel-0.19.0-installer-linux-x86_64.sh\n",
            "Resolving github.com (github.com)... 192.30.253.113, 192.30.253.112\n",
            "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/20773773/29a1a380-db91-11e8-989d-4be7267c69ab?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20181031%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20181031T184159Z&X-Amz-Expires=300&X-Amz-Signature=378cc67875518310a2aea765a8290fe785bd2688c369bfefb96d200a30651a89&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dbazel-0.19.0-installer-linux-x86_64.sh&response-content-type=application%2Foctet-stream [following]\n",
            "--2018-10-31 18:41:59--  https://github-production-release-asset-2e65be.s3.amazonaws.com/20773773/29a1a380-db91-11e8-989d-4be7267c69ab?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20181031%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20181031T184159Z&X-Amz-Expires=300&X-Amz-Signature=378cc67875518310a2aea765a8290fe785bd2688c369bfefb96d200a30651a89&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dbazel-0.19.0-installer-linux-x86_64.sh&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.100.251\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.100.251|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 166413740 (159M) [application/octet-stream]\n",
            "Saving to: ‘bazel-0.19.0-installer-linux-x86_64.sh’\n",
            "\n",
            "bazel-0.19.0-instal 100%[===================>] 158.70M  35.7MB/s    in 5.0s    \n",
            "\n",
            "2018-10-31 18:42:04 (31.4 MB/s) - ‘bazel-0.19.0-installer-linux-x86_64.sh’ saved [166413740/166413740]\n",
            "\n",
            "Bazel installer\n",
            "---------------\n",
            "\n",
            "Bazel is bundled with software licensed under the GPLv2 with Classpath exception.\n",
            "You can find the sources next to the installer on our release page:\n",
            "   https://github.com/bazelbuild/bazel/releases\n",
            "\n",
            "# Release 0.19.0 (2018-10-29)\n",
            "\n",
            "Baseline: ac880418885061d1039ad6b3d8c28949782e02d6\n",
            "\n",
            "Cherry picks:\n",
            "\n",
            "   + 9bc3b20053a8b99bf2c4a31323a7f96fabb9f1ec:\n",
            "     Fix the \"nojava\" platform and enable full presubmit checks for\n",
            "     the various JDK platforms now that we have enough GCE resources.\n",
            "   + 54c2572a8cabaf2b29e58abe9f04327314caa6a0:\n",
            "     Add openjdk_linux_archive java_toolchain for nojava platform.\n",
            "   + 20bfdc67dc1fc32ffebbda7088ba49ee17e3e182:\n",
            "     Automated rollback of commit\n",
            "     19a401c38e30ebc0879925a5caedcbe43de0028f.\n",
            "   + 914b4ce14624171a97ff8b41f9202058f10d15b2:\n",
            "     Windows: Fix Precondition check for addDynamicInputLinkOptions\n",
            "   + 83d406b7da32d1b1f6dd02eae2fe98582a4556fd:\n",
            "     Windows, test-setup.sh: Setting RUNFILES_MANIFEST_FILE only when\n",
            "     it exists.\n",
            "   + e025726006236520f7e91e196b9e7f139e0af5f4:\n",
            "     Update turbine\n",
            "   + 5f312dd1678878fb7563eae0cd184f2270346352:\n",
            "     Fix event id for action_completed BEP events\n",
            "\n",
            "The Bazel team is happy to announce a new version of Bazel, [Bazel 0.19](https://github.com/bazelbuild/bazel/releases/tag/0.19.0).\n",
            "\n",
            "This document lists the major changes since Bazel 0.18.\n",
            "\n",
            "General changes\n",
            "---------------\n",
            "\n",
            "* The `--incompatible_expand_directories` flag will automatically expand directories in command lines. Design doc: https://docs.google.com/document/d/11agWFiOUiz2htBLj6swPTob5z78TrCxm8DQE4uJLOwM\n",
            "\n",
            "* The `--loading_phase_threads` flag now defaults to `auto` (not 200, as was previously the case), which at the moment corresponds to the number of CPUs. This is appropriate for most users. However, if your sources reside on a network file system, increasing this value may yield better analysis-time performance when disk caches are cold.\n",
            "\n",
            "Android\n",
            "-------\n",
            "\n",
            "* Fixed missing debug symbols when building native code with `--compilation_mode=dbg` that target Android ARM architectures by adding the `-g` flag.\n",
            "\n",
            "C++\n",
            "---\n",
            "\n",
            "* Added `--incompatible_disable_legacy_flags_cc_toolchain_api` to deprecate legacy `cc_toolchain` Starlark API for legacy CROSSTOOL fields. Tracking issue is #6434. Migration docs are on the bazel website.\n",
            "\n",
            "* Runfiles in cc_test: the C++ runfiles library (`@bazel_tools//tools/cpp/runfiles`) can now create Runfiles objects for tests. See `//tools/cpp/runfiles/runfiles_src.h` (in the Bazel source tree) for documentation.\n",
            "\n",
            "* :cc_binary link action no longer hardcodes `-static-libgcc` for toolchains that support embedded runtimes (guarded by `--experimental_dont_emit_static_libgcc` temporarily).\n",
            "\n",
            "* The flag `--experimental_enable_cc_configuration_make_variables` is removed, use `--incompatible_disable_cc_configuration_make_variables` instead.\n",
            "\n",
            "Java\n",
            "----\n",
            "\n",
            "* If the `--javabase` flag is unset, Bazel locates a JDK using the `JAVA_HOME` environment variable and searching the PATH. If no JDK is found `--javabase` will be empty, and builds targeting Java will not be supported.  Previously Bazel would fall back to using the embedded JDK as a `--javabase`, but this is no longer default behaviour. A JDK should be explicitly installed instead to enable Java development.\n",
            "\n",
            "Code Coverage\n",
            "-------------\n",
            "\n",
            "* LcovMerger was renamed to CoverageOutputGenerator.\n",
            "\n",
            "* Faster coverage collection for gcc compiled C++ code can now be tested by enabling it with `--experimental_cc_coverage`.\n",
            "\n",
            "Other Changes\n",
            "-------------\n",
            "\n",
            "* Add `--apple_compiler` and `--apple_grte_top options`. These provide the equivalent of --compiler / --grte_top for the toolchain configured in --apple_crosstool_top.\n",
            "\n",
            "* There is now a `same_pkg_direct_rdeps` query function. See the query documentation for more details.\n",
            "\n",
            "* Propagating remote errors to the user even if `--verbose_failures=false` is set.\n",
            "\n",
            "* Add number of configured targets to analysis phase status output.\n",
            "\n",
            "* Bazel will now check stderr instead of stdout to decide if it is outputting to a terminal.  `--isatty` is deprecated, use `--is_stderr_atty` instead.\n",
            "\n",
            "Future Changes\n",
            "--------------\n",
            "\n",
            "* None of the C++ related incompatible flags mentioned in the 0.18 release were flipped, they will be flipped in the next release (0.20). We have created tracking issues for all the relevant incompatible flags:\n",
            "    * [`--incompatible_disable_late_bound_option_defaults`](https://docs.bazel.build/versions/master/skylark/backward-compatibility.html#disable-late-bound-option-defaults): #6384\n",
            "    * [`--incompatible_disable_depset_in_cc_user_flags`](https://docs.bazel.build/versions/master/skylark/backward-compatibility.html#disable-depsets-in-c-toolchain-api-in-user-flags): #6383\n",
            "    * [`--incompatible_disable_cc_toolchain_label_from_crosstool_proto`](https://docs.bazel.build/versions/master/skylark/backward-compatibility.html#disallow-using-crosstool-to-select-the-cc_toolchain-label): #6382\n",
            "    * [`--incompatible_disable_cc_configuration_make_variables`](https://github.com/bazelbuild/bazel/issues/6381): #6381\n",
            "    * [`--incompatible_disable_legacy_cpp_toolchain_skylark_api`](https://docs.bazel.build/versions/master/skylark/backward-compatibility.html#disable-legacy-c-configuration-api): #6380\n",
            "    * [`incompatible_disable_legacy_flags_cc_toolchain_api`](https://docs.bazel.build/versions/master/skylark/backward-compatibility.html#disable-legacy-c-toolchain-api): #6434\n",
            "\n",
            "* In the 0.20 release the flags [`--incompatible_remove_native_git_repository`](https://docs.bazel.build/versions/master/skylark/backward-compatibility.html#remove-native-git-repository) and [`--incompatible_remove_native_http_archive`](https://docs.bazel.build/versions/master/skylark/backward-compatibility.html#remove-native-http-archive) will be turned on.\n",
            "\n",
            "Thank you to our contributors!\n",
            "------------------------------\n",
            "\n",
            "This release contains contributions from many people at Google, as well as Andreas Herrmann, Andreas Hippler, Benjamin Peterson, David Ostrovsky, Ed Baunton, George Gensure, Igal Tabachnik, Jason Gavris, Loo Rong Jie, rmalik, and Yannic Bonenberger\n",
            "\n",
            "Thank you to everyone who contributed to this release!\n",
            "\n",
            "## Build informations\n",
            "   - [Commit](https://github.com/bazelbuild/bazel/commit/f0c844c)\n",
            "Uncompressing.......\n",
            "\n",
            "Bazel is now installed!\n",
            "\n",
            "Make sure you have \"/root/bin\" in your path. You can also activate bash\n",
            "completion by adding the following line to your ~/.bashrc:\n",
            "  source /root/.bazel/bin/bazel-complete.bash\n",
            "\n",
            "See http://bazel.build/docs/getting-started.html to start a new project!\n",
            "Cloning into 'adanet'...\n",
            "remote: Enumerating objects: 140, done.\u001b[K\n",
            "remote: Counting objects: 100% (140/140), done.\u001b[K\n",
            "remote: Compressing objects: 100% (95/95), done.\u001b[K\n",
            "remote: Total 610 (delta 77), reused 92 (delta 45), pack-reused 470\u001b[K\n",
            "Receiving objects: 100% (610/610), 475.87 KiB | 1.89 MiB/s, done.\n",
            "Resolving deltas: 100% (419/419), done.\n",
            "Extracting Bazel installation...\n",
            "WARNING: ignoring LD_PRELOAD in environment.\n",
            "Starting local Bazel server and connecting to it...\n",
            "\u001b[32mLoading:\u001b[0m 0 packages loaded\n",
            "\u001b[32mAnalyzing:\u001b[0m target //adanet/pip_package:build_pip_package (1 packages loaded)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //adanet/pip_package:build_pip_package (2 packages loaded)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //adanet/pip_package:build_pip_package (3 packages loaded, 0\\\n",
            "\u001b[32mAnalyzing:\u001b[0m target //adanet/pip_package:build_pip_package (4 packages loaded, 1\\\n",
            "\u001b[32mAnalyzing:\u001b[0m target //adanet/pip_package:build_pip_package (8 packages loaded, 3\\\n",
            "6 targets configured)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //adanet/pip_package:build_pip_package (12 packages loaded, \\\n",
            "42 targets configured)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //adanet/pip_package:build_pip_package (13 packages loaded, \\\n",
            "76 targets configured)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //adanet/pip_package:build_pip_package (13 packages loaded, \\\n",
            "89 targets configured)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //adanet/pip_package:build_pip_package (13 packages loaded, \\\n",
            "89 targets configured)\n",
            "    currently loading: adanet/core\n",
            "\u001b[32mAnalyzing:\u001b[0m target //adanet/pip_package:build_pip_package (13 packages loaded, \\\n",
            "89 targets configured)\n",
            "    currently loading: adanet/core\n",
            "\u001b[32mAnalyzing:\u001b[0m target //adanet/pip_package:build_pip_package (13 packages loaded, \\\n",
            "89 targets configured)\n",
            "    currently loading: adanet/core\n",
            "\u001b[32mAnalyzing:\u001b[0m target //adanet/pip_package:build_pip_package (13 packages loaded, \\\n",
            "89 targets configured)\n",
            "\u001b[32mINFO: \u001b[0mSHA256 (https://github.com/google/protobuf/archive/ab8edf1dbe2237b4717869eaab11a2998541ad8d.tar.gz) = 56541023a5dfa05de7dd5b7856bfd370047d6b93718eba068b43d1a4092b6cb6\n",
            "\u001b[32mAnalyzing:\u001b[0m target //adanet/pip_package:build_pip_package (13 packages loaded, \\\n",
            "89 targets configured)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //adanet/pip_package:build_pip_package (14 packages loaded, \\\n",
            "100 targets configured)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //adanet/pip_package:build_pip_package (15 packages loaded, \\\n",
            "104 targets configured)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //adanet/pip_package:build_pip_package (17 packages loaded, \\\n",
            "\u001b[32mAnalyzing:\u001b[0m target //adanet/pip_package:build_pip_package (17 packages loaded, \\\n",
            "125 targets configured)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //adanet/pip_package:build_pip_package (17 packages loaded, \\\n",
            "\u001b[32mINFO: \u001b[0mSHA256 (https://github.com/google/protobuf/archive/v3.6.0.zip) = e514c2e613dc47c062ea8df480efeec368ffbef98af0437ac00cdaadcb0d80d2\n",
            "\u001b[32mAnalyzing:\u001b[0m target //adanet/pip_package:build_pip_package (17 packages loaded, \\\n",
            "\u001b[32mAnalyzing:\u001b[0m target //adanet/pip_package:build_pip_package (17 packages loaded, \\\n",
            "125 targets configured)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //adanet/pip_package:build_pip_package (18 packages loaded, \\\n",
            "\u001b[32mINFO: \u001b[0mAnalysed target //adanet/pip_package:build_pip_package (18 packages loaded, 608 targets configured).\n",
            "\u001b[32mINFO: \u001b[0mFound 1 target...\n",
            "\u001b[32m[4 / 9]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 0s processwrapper-sandbox\n",
            "\u001b[32m[4 / 9]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[4 / 9]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[4 / 9]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[5 / 9]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protobuf_lite; 3s processwrapper-sandbox\n",
            "\u001b[32m[5 / 9]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 3s processwrapper-sandbox\n",
            "\u001b[32m[6 / 10]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[6 / 10]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[6 / 10]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[7 / 11]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 4s processwrapper-sandbox\n",
            "\u001b[32m[7 / 11]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 5s processwrapper-sandbox\n",
            "\u001b[32m[7 / 11]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 6s processwrapper-sandbox\n",
            "\u001b[32m[9 / 13]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 0s processwrapper-sandbox\n",
            "\u001b[32m[10 / 14]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[11 / 15]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 0s processwrapper-sandbox\n",
            "\u001b[32m[11 / 15]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 0s processwrapper-sandbox\n",
            "\u001b[32m[11 / 15]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[12 / 16]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[12 / 16]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[14 / 18]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protobuf; 0s processwrapper-sandbox\n",
            "\u001b[32m[14 / 18]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 0s processwrapper-sandbox\n",
            "\u001b[32m[14 / 18]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[15 / 19]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[15 / 19]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[15 / 19]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[16 / 20]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[16 / 20]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[17 / 21]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protoc_lib; 0s processwrapper-sandbox\n",
            "\u001b[32m[17 / 21]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 0s processwrapper-sandbox\n",
            "\u001b[32m[18 / 22]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[19 / 23]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[19 / 23]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[20 / 24]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[20 / 24]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[21 / 25]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 0s processwrapper-sandbox\n",
            "\u001b[32m[23 / 30]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 0s processwrapper-sandbox\n",
            "\u001b[32m[23 / 30]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 0s processwrapper-sandbox\n",
            "\u001b[32m[24 / 31]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[27 / 34]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[27 / 34]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[28 / 35]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[28 / 35]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[29 / 36]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[29 / 36]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[30 / 37]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[30 / 37]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 3s processwrapper-sandbox\n",
            "\u001b[32m[30 / 37]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 4s processwrapper-sandbox\n",
            "\u001b[32m[31 / 38]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 5s processwrapper-sandbox\n",
            "\u001b[32m[32 / 39]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[32 / 39]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[33 / 40]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[34 / 41]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 0s processwrapper-sandbox\n",
            "\u001b[32m[35 / 42]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[35 / 42]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[35 / 42]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 3s processwrapper-sandbox\n",
            "\u001b[32m[36 / 43]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[36 / 43]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[36 / 43]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 3s processwrapper-sandbox\n",
            "\u001b[32m[36 / 43]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 4s processwrapper-sandbox\n",
            "\u001b[32m[36 / 43]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 5s processwrapper-sandbox\n",
            "\u001b[32m[37 / 44]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[37 / 44]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[38 / 45]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[38 / 45]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[39 / 46]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[40 / 47]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 1s processwrapper-sandbox\n",
            "\u001b[32m[41 / 48]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[42 / 49]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[42 / 49]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[43 / 50]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[43 / 50]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[44 / 51]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 1s processwrapper-sandbox\n",
            "\u001b[32m[45 / 52]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[45 / 52]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[46 / 53]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 3s processwrapper-sandbox\n",
            "\u001b[32m[47 / 55]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[47 / 55]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[47 / 55]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[48 / 56]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[48 / 56]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 3s processwrapper-sandbox\n",
            "\u001b[32m[49 / 57]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[50 / 58]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 0s processwrapper-sandbox\n",
            "\u001b[32m[51 / 59]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[51 / 59]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[52 / 60]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[52 / 60]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[52 / 60]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[52 / 60]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 4s processwrapper-sandbox\n",
            "\u001b[32m[54 / 62]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 5s processwrapper-sandbox\n",
            "\u001b[32m[54 / 62]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 6s processwrapper-sandbox\n",
            "\u001b[32m[54 / 62]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 7s processwrapper-sandbox\n",
            "\u001b[32m[55 / 63]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[56 / 64]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[56 / 64]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[56 / 64]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 3s processwrapper-sandbox\n",
            "\u001b[32m[56 / 64]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 4s processwrapper-sandbox\n",
            "\u001b[32m[57 / 65]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 5s processwrapper-sandbox\n",
            "\u001b[32m[57 / 65]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 6s processwrapper-sandbox\n",
            "\u001b[32m[57 / 65]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 7s processwrapper-sandbox\n",
            "\u001b[32m[57 / 65]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 8s processwrapper-sandbox\n",
            "\u001b[32m[58 / 66]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 8s processwrapper-sandbox\n",
            "\u001b[32m[58 / 66]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 8s processwrapper-sandbox\n",
            "\u001b[32m[58 / 66]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 9s processwrapper-sandbox\n",
            "\u001b[32m[59 / 67]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 11s processwrapper-sandbox\n",
            "\u001b[32m[59 / 67]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 12s processwrapper-sandbox\n",
            "\u001b[32m[59 / 67]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 13s processwrapper-sandbox\n",
            "\u001b[32m[59 / 67]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 14s processwrapper-sandbox\n",
            "\u001b[32m[59 / 67]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 15s processwrapper-sandbox\n",
            "\u001b[32m[59 / 67]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 16s processwrapper-sandbox\n",
            "\u001b[32m[60 / 68]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 16s processwrapper-sandbox\n",
            "\u001b[32m[61 / 69]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[62 / 70]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[62 / 70]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[63 / 71]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[63 / 71]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[63 / 71]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 3s processwrapper-sandbox\n",
            "\u001b[32m[64 / 72]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 5s processwrapper-sandbox\n",
            "\u001b[32m[65 / 73]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 0s processwrapper-sandbox\n",
            "\u001b[32m[65 / 73]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 0s processwrapper-sandbox\n",
            "\u001b[32m[66 / 74]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 0s processwrapper-sandbox\n",
            "\u001b[32m[66 / 74]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[67 / 75]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[67 / 75]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[67 / 75]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[67 / 75]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[68 / 76]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[68 / 76]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 3s processwrapper-sandbox\n",
            "\u001b[32m[68 / 76]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 4s processwrapper-sandbox\n",
            "\u001b[32m[69 / 77]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 5s processwrapper-sandbox\n",
            "\u001b[32m[70 / 78]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 0s processwrapper-sandbox\n",
            "\u001b[32m[70 / 78]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[70 / 78]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[72 / 80]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 0s processwrapper-sandbox\n",
            "\u001b[32m[72 / 80]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[72 / 80]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[74 / 82]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 0s processwrapper-sandbox\n",
            "\u001b[32m[74 / 82]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[74 / 82]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[74 / 82]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[75 / 83]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[76 / 84]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 0s processwrapper-sandbox\n",
            "\u001b[32m[76 / 84]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[76 / 84]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[78 / 86]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 0s processwrapper-sandbox\n",
            "\u001b[32m[78 / 86]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[79 / 87]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[80 / 88]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[82 / 90]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 0s processwrapper-sandbox\n",
            "\u001b[32m[83 / 91]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[83 / 91]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[83 / 91]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[84 / 92]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[85 / 93]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[85 / 93]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[87 / 95]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 0s processwrapper-sandbox\n",
            "\u001b[32m[87 / 95]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[87 / 95]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[87 / 95]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 3s processwrapper-sandbox\n",
            "\u001b[32m[88 / 96]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 3s processwrapper-sandbox\n",
            "\u001b[32m[89 / 97]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[90 / 98]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[90 / 98]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[90 / 98]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[92 / 100]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 0s processwrapper-sandbox\n",
            "\u001b[32m[93 / 101]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[94 / 102]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[94 / 102]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[95 / 103]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[95 / 103]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[95 / 103]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 4s processwrapper-sandbox\n",
            "\u001b[32m[95 / 103]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 5s processwrapper-sandbox\n",
            "\u001b[32m[96 / 104]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 6s processwrapper-sandbox\n",
            "\u001b[32m[96 / 104]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 7s processwrapper-sandbox\n",
            "\u001b[32m[97 / 105]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[97 / 105]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[97 / 105]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[97 / 105]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 3s processwrapper-sandbox\n",
            "\u001b[32m[98 / 106]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 4s processwrapper-sandbox\n",
            "\u001b[32m[98 / 106]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 5s processwrapper-sandbox\n",
            "\u001b[32m[98 / 106]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 6s processwrapper-sandbox\n",
            "\u001b[32m[99 / 107]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[99 / 107]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 4s processwrapper-sandbox\n",
            "\u001b[32m[100 / 108]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[101 / 109]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[101 / 109]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[101 / 109]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[103 / 111]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 0s processwrapper-sandbox\n",
            "\u001b[32m[104 / 112]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[104 / 112]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[104 / 112]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 3s processwrapper-sandbox\n",
            "\u001b[32m[105 / 113]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 3s processwrapper-sandbox\n",
            "\u001b[32m[105 / 113]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 3s processwrapper-sandbox\n",
            "\u001b[32m[106 / 114]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[106 / 114]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[106 / 114]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[107 / 115]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[107 / 115]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[108 / 116]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[108 / 116]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[110 / 118]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 0s processwrapper-sandbox\n",
            "\u001b[32m[110 / 118]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[110 / 118]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[110 / 118]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 3s processwrapper-sandbox\n",
            "\u001b[32m[110 / 118]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 4s processwrapper-sandbox\n",
            "\u001b[32m[110 / 118]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 5s processwrapper-sandbox\n",
            "\u001b[32m[110 / 118]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 6s processwrapper-sandbox\n",
            "\u001b[32m[111 / 119]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 6s processwrapper-sandbox\n",
            "\u001b[32m[111 / 119]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 6s processwrapper-sandbox\n",
            "\u001b[32m[111 / 119]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 7s processwrapper-sandbox\n",
            "\u001b[32m[111 / 119]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 8s processwrapper-sandbox\n",
            "\u001b[32m[112 / 120]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 9s processwrapper-sandbox\n",
            "\u001b[32m[112 / 120]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 10s processwrapper-sandbox\n",
            "\u001b[32m[112 / 120]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 11s processwrapper-sandbox\n",
            "\u001b[32m[112 / 120]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 12s processwrapper-sandbox\n",
            "\u001b[32m[113 / 121]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[114 / 122]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 0s processwrapper-sandbox\n",
            "\u001b[32m[114 / 122]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 0s processwrapper-sandbox\n",
            "\u001b[32m[114 / 122]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 1s processwrapper-sandbox\n",
            "\u001b[32m[115 / 123]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[115 / 123]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[116 / 124]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 0s processwrapper-sandbox\n",
            "\u001b[32m[116 / 124]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[116 / 124]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[118 / 126]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 0s processwrapper-sandbox\n",
            "\u001b[32m[119 / 126]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[119 / 126]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[120 / 127]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[120 / 127]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[121 / 128]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[121 / 128]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[122 / 129]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[122 / 129]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[123 / 130]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[124 / 131]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[125 / 132]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[126 / 133]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[126 / 133]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[126 / 133]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[127 / 134]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 4s processwrapper-sandbox\n",
            "\u001b[32m[127 / 134]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 5s processwrapper-sandbox\n",
            "\u001b[32m[128 / 135]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 1s processwrapper-sandbox\n",
            "\u001b[32m[128 / 135]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 2s processwrapper-sandbox\n",
            "\u001b[32m[129 / 136]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[130 / 136]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protoc_lib; 0s processwrapper-sandbox\n",
            "\u001b[32m[133 / 137]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 0s processwrapper-sandbox\n",
            "\u001b[32m[133 / 137]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[133 / 137]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[134 / 138]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[134 / 138]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 4s processwrapper-sandbox\n",
            "\u001b[32m[135 / 139]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[135 / 139]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[136 / 140]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[136 / 140]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[137 / 141]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[138 / 142]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[138 / 142]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[139 / 143]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[140 / 144]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 0s processwrapper-sandbox\n",
            "\u001b[32m[140 / 144]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 0s processwrapper-sandbox\n",
            "\u001b[32m[140 / 144]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[140 / 144]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[141 / 145]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[142 / 146]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 0s processwrapper-sandbox\n",
            "\u001b[32m[143 / 147]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 0s processwrapper-sandbox\n",
            "\u001b[32m[143 / 147]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 0s processwrapper-sandbox\n",
            "\u001b[32m[143 / 147]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[144 / 148]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[146 / 150]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 0s processwrapper-sandbox\n",
            "\u001b[32m[146 / 150]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 0s processwrapper-sandbox\n",
            "\u001b[32m[146 / 150]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[146 / 150]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[147 / 151]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[147 / 151]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[147 / 151]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 3s processwrapper-sandbox\n",
            "\u001b[32m[148 / 152]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[148 / 152]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[149 / 153]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[150 / 154]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[151 / 155]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[151 / 155]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[152 / 156]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[152 / 156]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[153 / 157]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[154 / 158]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 0s processwrapper-sandbox\n",
            "\u001b[32m[154 / 158]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[155 / 159]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[155 / 159]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 3s processwrapper-sandbox\n",
            "\u001b[32m[155 / 159]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 4s processwrapper-sandbox\n",
            "\u001b[32m[156 / 160]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 5s processwrapper-sandbox\n",
            "\u001b[32m[156 / 160]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 6s processwrapper-sandbox\n",
            "\u001b[32m[156 / 160]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 7s processwrapper-sandbox\n",
            "\u001b[32m[157 / 161]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 8s processwrapper-sandbox\n",
            "\u001b[32m[157 / 161]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 9s processwrapper-sandbox\n",
            "\u001b[32m[158 / 162]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[159 / 163]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 0s processwrapper-sandbox\n",
            "\u001b[32m[159 / 163]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 0s processwrapper-sandbox\n",
            "\u001b[32m[159 / 163]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[160 / 164]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[161 / 165]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[162 / 166]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[163 / 167]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 0s processwrapper-sandbox\n",
            "\u001b[32m[163 / 167]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 0s processwrapper-sandbox\n",
            "\u001b[32m[164 / 168]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 1s processwrapper-sandbox\n",
            "\u001b[32m[166 / 170]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 0s processwrapper-sandbox\n",
            "\u001b[32m[166 / 170]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 1s processwrapper-sandbox\n",
            "\u001b[32m[166 / 170]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf_lite; 2s processwrapper-sandbox\n",
            "\u001b[32m[167 / 171]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[167 / 171]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[168 / 172]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[169 / 173]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 2s processwrapper-sandbox\n",
            "\u001b[32m[170 / 174]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 0s processwrapper-sandbox\n",
            "\u001b[32m[170 / 174]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32m[171 / 175]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 2s processwrapper-sandbox\n",
            "\u001b[32m[171 / 175]\u001b[0m 2 actions running\n",
            "    @com_google_protobuf//:protobuf; 3s processwrapper-sandbox\n",
            "\u001b[32m[172 / 177]\u001b[0m 2 actions, 1 running\n",
            "    @com_google_protobuf//:protoc_lib; 1s processwrapper-sandbox\n",
            "\u001b[32mINFO: \u001b[0mFrom ProtoCompile external/com_google_protobuf/python/google/protobuf/any_pb2.py:\n",
            "external/com_google_protobuf/python: warning: directory does not exist.\n",
            "Target //adanet/pip_package:build_pip_package up-to-date:\n",
            "  bazel-bin/adanet/pip_package/build_pip_package\n",
            "\u001b[32mINFO: \u001b[0mElapsed time: 264.260s, Critical Path: 17.71s, Remote (0.00% of the time): [queue: 0.00%, setup: 0.00%, process: 0.00%]\n",
            "\u001b[32mINFO: \u001b[0m170 processes: 170 processwrapper-sandbox.\n",
            "\u001b[32mINFO:\u001b[0m Build completed successfully, 180 total actions\n",
            "\u001b[0mWed Oct 31 18:46:41 UTC 2018 : === Using tmpdir: /tmp/EifrTUF0fQQtDmj60RRNX69_adanet_pip_pkg\n",
            "\u001b[32mAnalyzing:\u001b[0m target //adanet/pip_package:build_pip_package (0 packages loaded, 0\\\n",
            "\u001b[32mINFO: \u001b[0mAnalysed target //adanet/pip_package:build_pip_package (0 packages loaded, 0 targets configured).\n",
            "\u001b[32mINFO: \u001b[0mFound 1 target...\n",
            "Target //adanet/pip_package:build_pip_package up-to-date:\n",
            "  bazel-bin/adanet/pip_package/build_pip_package\n",
            "\u001b[32mINFO: \u001b[0mElapsed time: 0.316s, Critical Path: 0.00s, Remote (0.00% of the time): [queue: 0.00%, setup: 0.00%, process: 0.00%]\n",
            "\u001b[32mINFO: \u001b[0m0 processes.\n",
            "\u001b[32mINFO:\u001b[0m Build completed successfully, 1 total action\n",
            "\u001b[0m/tmp/EifrTUF0fQQtDmj60RRNX69_adanet_pip_pkg /content/adanet\n",
            "Wed Oct 31 18:46:41 UTC 2018 : === Building universal python wheel in /tmp/EifrTUF0fQQtDmj60RRNX69_adanet_pip_pkg\n",
            "/content/adanet\n",
            "Wed Oct 31 18:46:42 UTC 2018 : === Output wheel files are in: /tmp/adanet_pkg\n",
            "Processing /tmp/adanet_pkg/adanet-0.1.0.dev0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python2.7/dist-packages (from adanet==0.1.0.dev0) (3.6.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python2.7/dist-packages (from adanet==0.1.0.dev0) (1.14.6)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python2.7/dist-packages (from adanet==0.1.0.dev0) (1.11.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python2.7/dist-packages (from protobuf>=3.4.0->adanet==0.1.0.dev0) (40.5.0)\n",
            "Installing collected packages: adanet\n",
            "Successfully installed adanet-0.1.0.dev0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "q4WF3l23pumU"
      },
      "cell_type": "markdown",
      "source": [
        "##### Copyright 2018 The AdaNet Authors."
      ]
    },
    {
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "Kic2quJWppmx",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "aL7SpaKdirqG"
      },
      "cell_type": "markdown",
      "source": [
        "# Customizing AdaNet\n",
        "\n",
        "Often times, as a researcher or machine learning practitioner, you will have\n",
        "some prior knowledge about a dataset. Ideally you should be able to encode that\n",
        "knowledge into your machine learning algorithm. With `adanet`, you can do so by\n",
        "defining the *neural architecture search space* that the AdaNet algorithm should\n",
        "explore.\n",
        "\n",
        "In this tutorial, we will explore the flexibility of the `adanet` framework, and\n",
        "create a custom search space for an image-classificatio dataset using high-level\n",
        "TensorFlow libraries like `tf.layers`.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "x_3b6xx2s6B9",
        "colab": {
          "test": {
            "output": "ignore",
            "timeout": 900
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import functools\n",
        "\n",
        "import adanet\n",
        "#from adanet.examples import simple_dnn\n",
        "import tensorflow as tf\n",
        "\n",
        "# The random seed to use.\n",
        "RANDOM_SEED = 42"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "7gE5Mm9j2oYw"
      },
      "cell_type": "markdown",
      "source": [
        "## Fashion MNIST dataset\n",
        "\n",
        "In this example, we will use the Fashion MNIST dataset\n",
        "[[Xiao et al., 2017](https://arxiv.org/abs/1708.07747)] for classifying fashion\n",
        "apparel images into one of ten categories:\n",
        "\n",
        "1.  T-shirt/top\n",
        "2.  Trouser\n",
        "3.  Pullover\n",
        "4.  Dress\n",
        "5.  Coat\n",
        "6.  Sandal\n",
        "7.  Shirt\n",
        "8.  Sneaker\n",
        "9.  Bag\n",
        "10. Ankle boot\n",
        "\n",
        "![Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist/blob/master/doc/img/fashion-mnist-sprite.png?raw=true)"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "5_hRtdchqRZb"
      },
      "cell_type": "markdown",
      "source": [
        "## Download the data\n",
        "\n",
        "Conveniently, the data is available via Keras:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "uYklOnPJ4h7g",
        "colab": {
          "test": {
            "output": "ignore",
            "timeout": 900
          }
        }
      },
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = (\n",
        "    tf.keras.datasets.fashion_mnist.load_data())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "tECo5dFd4QCa"
      },
      "cell_type": "markdown",
      "source": [
        "## Supply the data in TensorFlow\n",
        "\n",
        "Our first task is to supply the data in TensorFlow. Using the\n",
        "tf.estimator.Estimator covention, we will define a function that returns an\n",
        "`input_fn` which returns feature and label `Tensors`.\n",
        "\n",
        "We will also use the `tf.data.Dataset` API to feed the data into our models."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gxTAoIXwsTH7",
        "colab": {
          "test": {
            "output": "ignore",
            "timeout": 900
          }
        }
      },
      "cell_type": "code",
      "source": [
        "FEATURES_KEY = \"images\"\n",
        "\n",
        "\n",
        "def generator(images, labels):\n",
        "  \"\"\"Returns a generator that returns image-label pairs.\"\"\"\n",
        "\n",
        "  def _gen():\n",
        "    for image, label in zip(images, labels):\n",
        "      yield image, label\n",
        "\n",
        "  return _gen\n",
        "\n",
        "\n",
        "def preprocess_image(image, label):\n",
        "  \"\"\"Preprocesses an image for an `Estimator`.\"\"\"\n",
        "  # First let's scale the pixel values to be between 0 and 1.\n",
        "  image = image / 255.\n",
        "  # Next we reshape the image so that we can apply a 2D convolution to it.\n",
        "  image = tf.reshape(image, [28, 28, 1])\n",
        "  # Finally the features need to be supplied as a dictionary.\n",
        "  features = {FEATURES_KEY: image}\n",
        "  return features, label\n",
        "\n",
        "\n",
        "def input_fn(partition, training, batch_size):\n",
        "  \"\"\"Generate an input_fn for the Estimator.\"\"\"\n",
        "\n",
        "  def _input_fn():\n",
        "    if partition == \"train\":\n",
        "      dataset = tf.data.Dataset.from_generator(\n",
        "          generator(x_train, y_train), (tf.float32, tf.int32), ((28, 28), ()))\n",
        "    else:\n",
        "      dataset = tf.data.Dataset.from_generator(\n",
        "          generator(x_test, y_test), (tf.float32, tf.int32), ((28, 28), ()))\n",
        "\n",
        "    # We call repeat after shuffling, rather than before, to prevent separate\n",
        "    # epochs from blending together.\n",
        "    if training:\n",
        "      dataset = dataset.shuffle(10 * batch_size, seed=RANDOM_SEED).repeat()\n",
        "\n",
        "    dataset = dataset.map(preprocess_image).batch(batch_size)\n",
        "    iterator = dataset.make_one_shot_iterator()\n",
        "    features, labels = iterator.get_next()\n",
        "    return features, labels\n",
        "\n",
        "  return _input_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "vm9yudEv5lQZ"
      },
      "cell_type": "markdown",
      "source": [
        "## Establish baselines\n",
        "\n",
        "The next task should be to get somes baselines to see how our model performs on\n",
        "this dataset.\n",
        "\n",
        "Let's define some information to share with all our `tf.estimator.Estimators`:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "xNwSUWh-9_Ib",
        "colab": {
          "test": {
            "output": "ignore",
            "timeout": 900
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# The number of classes.\n",
        "NUM_CLASSES = 10\n",
        "\n",
        "# We will average the losses in each mini-batch when computing gradients.\n",
        "loss_reduction = tf.losses.Reduction.SUM_OVER_BATCH_SIZE\n",
        "\n",
        "# A `Head` instance defines the loss function and metrics for `Estimators`.\n",
        "head = tf.contrib.estimator.multi_class_head(\n",
        "    NUM_CLASSES, loss_reduction=loss_reduction)\n",
        "\n",
        "# Some `Estimators` use feature columns for understanding their input features.\n",
        "feature_columns = [\n",
        "    tf.feature_column.numeric_column(FEATURES_KEY, shape=[28, 28, 1])\n",
        "]\n",
        "\n",
        "# Estimator configuration.\n",
        "config = tf.estimator.RunConfig(\n",
        "    save_checkpoints_steps=50000,\n",
        "    save_summary_steps=50000,\n",
        "    tf_random_seed=RANDOM_SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "QY0cv-ot-Gxs"
      },
      "cell_type": "markdown",
      "source": [
        "Let's start simple, and train a linear model:"
      ]
    },
    {
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "s8wJKsi06blX",
        "outputId": "c03af6d0-5546-4241-9e2e-8378882ef62b",
        "colab": {
          "test": {
            "output": "ignore",
            "timeout": 900
          },
          "base_uri": "https://localhost:8080/",
          "height": 2264
        }
      },
      "cell_type": "code",
      "source": [
        "#@test {\"skip\": true}\n",
        "#@title Parameters\n",
        "LEARNING_RATE = 0.001  #@param {type:\"number\"}\n",
        "TRAIN_STEPS = 5000  #@param {type:\"integer\"}\n",
        "BATCH_SIZE = 64  #@param {type:\"integer\"}\n",
        "\n",
        "estimator = tf.estimator.LinearClassifier(\n",
        "    feature_columns=feature_columns,\n",
        "    n_classes=NUM_CLASSES,\n",
        "    optimizer=tf.train.RMSPropOptimizer(learning_rate=LEARNING_RATE),\n",
        "    loss_reduction=loss_reduction,\n",
        "    config=config)\n",
        "\n",
        "results, _ = tf.estimator.train_and_evaluate(\n",
        "    estimator,\n",
        "    train_spec=tf.estimator.TrainSpec(\n",
        "        input_fn=input_fn(\"train\", training=True, batch_size=BATCH_SIZE),\n",
        "        max_steps=TRAIN_STEPS),\n",
        "    eval_spec=tf.estimator.EvalSpec(\n",
        "        input_fn=input_fn(\"test\", training=False, batch_size=BATCH_SIZE),\n",
        "        steps=None))\n",
        "print(\"Accuracy:\", results[\"accuracy\"])\n",
        "print(\"Loss:\", results[\"average_loss\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpUyD8Tq\n",
            "INFO:tensorflow:Using config: {'_save_checkpoints_secs': None, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f57a6e08050>, '_model_dir': '/tmp/tmpUyD8Tq', '_protocol': None, '_save_checkpoints_steps': 50000, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_tf_random_seed': 42, '_save_summary_steps': 50000, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_master': ''}\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 50000 or save_checkpoints_secs None.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpUyD8Tq/model.ckpt.\n",
            "INFO:tensorflow:loss = 2.3025851, step = 0\n",
            "INFO:tensorflow:global_step/sec: 62.8435\n",
            "INFO:tensorflow:loss = 1.1483729, step = 100 (1.592 sec)\n",
            "INFO:tensorflow:global_step/sec: 58.4364\n",
            "INFO:tensorflow:loss = 0.5317185, step = 200 (1.712 sec)\n",
            "INFO:tensorflow:global_step/sec: 58.2213\n",
            "INFO:tensorflow:loss = 0.69215995, step = 300 (1.717 sec)\n",
            "INFO:tensorflow:global_step/sec: 56.7106\n",
            "INFO:tensorflow:loss = 0.54650015, step = 400 (1.764 sec)\n",
            "INFO:tensorflow:global_step/sec: 56.9788\n",
            "INFO:tensorflow:loss = 0.5904442, step = 500 (1.754 sec)\n",
            "INFO:tensorflow:global_step/sec: 57.7213\n",
            "INFO:tensorflow:loss = 0.502407, step = 600 (1.733 sec)\n",
            "INFO:tensorflow:global_step/sec: 57.3496\n",
            "INFO:tensorflow:loss = 0.4516151, step = 700 (1.743 sec)\n",
            "INFO:tensorflow:global_step/sec: 57.2516\n",
            "INFO:tensorflow:loss = 0.55855703, step = 800 (1.747 sec)\n",
            "INFO:tensorflow:global_step/sec: 57.8027\n",
            "INFO:tensorflow:loss = 0.45025253, step = 900 (1.730 sec)\n",
            "INFO:tensorflow:global_step/sec: 57.3457\n",
            "INFO:tensorflow:loss = 0.3062805, step = 1000 (1.744 sec)\n",
            "INFO:tensorflow:global_step/sec: 58.0998\n",
            "INFO:tensorflow:loss = 0.36369497, step = 1100 (1.721 sec)\n",
            "INFO:tensorflow:global_step/sec: 58.4241\n",
            "INFO:tensorflow:loss = 0.46128386, step = 1200 (1.712 sec)\n",
            "INFO:tensorflow:global_step/sec: 56.7976\n",
            "INFO:tensorflow:loss = 0.37242544, step = 1300 (1.761 sec)\n",
            "INFO:tensorflow:global_step/sec: 57.0239\n",
            "INFO:tensorflow:loss = 0.63520956, step = 1400 (1.754 sec)\n",
            "INFO:tensorflow:global_step/sec: 57.333\n",
            "INFO:tensorflow:loss = 0.644976, step = 1500 (1.744 sec)\n",
            "INFO:tensorflow:global_step/sec: 57.7622\n",
            "INFO:tensorflow:loss = 0.44837195, step = 1600 (1.731 sec)\n",
            "INFO:tensorflow:global_step/sec: 56.8564\n",
            "INFO:tensorflow:loss = 0.19677359, step = 1700 (1.759 sec)\n",
            "INFO:tensorflow:global_step/sec: 57.5045\n",
            "INFO:tensorflow:loss = 0.3082497, step = 1800 (1.739 sec)\n",
            "INFO:tensorflow:global_step/sec: 58.2185\n",
            "INFO:tensorflow:loss = 0.41565022, step = 1900 (1.718 sec)\n",
            "INFO:tensorflow:global_step/sec: 57.8253\n",
            "INFO:tensorflow:loss = 0.5047445, step = 2000 (1.729 sec)\n",
            "INFO:tensorflow:global_step/sec: 57.0617\n",
            "INFO:tensorflow:loss = 0.61880493, step = 2100 (1.753 sec)\n",
            "INFO:tensorflow:global_step/sec: 58.194\n",
            "INFO:tensorflow:loss = 0.2654074, step = 2200 (1.718 sec)\n",
            "INFO:tensorflow:global_step/sec: 57.3464\n",
            "INFO:tensorflow:loss = 0.6249703, step = 2300 (1.744 sec)\n",
            "INFO:tensorflow:global_step/sec: 57.1182\n",
            "INFO:tensorflow:loss = 0.46278533, step = 2400 (1.751 sec)\n",
            "INFO:tensorflow:global_step/sec: 57.2913\n",
            "INFO:tensorflow:loss = 0.36525694, step = 2500 (1.746 sec)\n",
            "INFO:tensorflow:global_step/sec: 57.4805\n",
            "INFO:tensorflow:loss = 0.5498886, step = 2600 (1.739 sec)\n",
            "INFO:tensorflow:global_step/sec: 57.2138\n",
            "INFO:tensorflow:loss = 0.8027371, step = 2700 (1.748 sec)\n",
            "INFO:tensorflow:global_step/sec: 57.2487\n",
            "INFO:tensorflow:loss = 0.35317737, step = 2800 (1.747 sec)\n",
            "INFO:tensorflow:global_step/sec: 57.1745\n",
            "INFO:tensorflow:loss = 0.40077132, step = 2900 (1.749 sec)\n",
            "INFO:tensorflow:global_step/sec: 57.3826\n",
            "INFO:tensorflow:loss = 0.4046799, step = 3000 (1.743 sec)\n",
            "INFO:tensorflow:global_step/sec: 57.3942\n",
            "INFO:tensorflow:loss = 0.3870784, step = 3100 (1.742 sec)\n",
            "INFO:tensorflow:global_step/sec: 57.2851\n",
            "INFO:tensorflow:loss = 0.48983034, step = 3200 (1.745 sec)\n",
            "INFO:tensorflow:global_step/sec: 57.2951\n",
            "INFO:tensorflow:loss = 0.44130424, step = 3300 (1.745 sec)\n",
            "INFO:tensorflow:global_step/sec: 57.0794\n",
            "INFO:tensorflow:loss = 0.44600236, step = 3400 (1.752 sec)\n",
            "INFO:tensorflow:global_step/sec: 57.7628\n",
            "INFO:tensorflow:loss = 0.3933785, step = 3500 (1.731 sec)\n",
            "INFO:tensorflow:global_step/sec: 58.3021\n",
            "INFO:tensorflow:loss = 0.39527544, step = 3600 (1.715 sec)\n",
            "INFO:tensorflow:global_step/sec: 57.5384\n",
            "INFO:tensorflow:loss = 0.5779325, step = 3700 (1.738 sec)\n",
            "INFO:tensorflow:global_step/sec: 57.0014\n",
            "INFO:tensorflow:loss = 0.34049267, step = 3800 (1.754 sec)\n",
            "INFO:tensorflow:global_step/sec: 56.7886\n",
            "INFO:tensorflow:loss = 0.24868615, step = 3900 (1.761 sec)\n",
            "INFO:tensorflow:global_step/sec: 57.3399\n",
            "INFO:tensorflow:loss = 0.42104775, step = 4000 (1.744 sec)\n",
            "INFO:tensorflow:global_step/sec: 57.2317\n",
            "INFO:tensorflow:loss = 0.5045029, step = 4100 (1.747 sec)\n",
            "INFO:tensorflow:global_step/sec: 57.7462\n",
            "INFO:tensorflow:loss = 0.4103522, step = 4200 (1.732 sec)\n",
            "INFO:tensorflow:global_step/sec: 56.779\n",
            "INFO:tensorflow:loss = 0.5953514, step = 4300 (1.761 sec)\n",
            "INFO:tensorflow:global_step/sec: 57.7154\n",
            "INFO:tensorflow:loss = 0.23190314, step = 4400 (1.733 sec)\n",
            "INFO:tensorflow:global_step/sec: 57.4828\n",
            "INFO:tensorflow:loss = 0.57092077, step = 4500 (1.740 sec)\n",
            "INFO:tensorflow:global_step/sec: 56.8079\n",
            "INFO:tensorflow:loss = 0.33438718, step = 4600 (1.760 sec)\n",
            "INFO:tensorflow:global_step/sec: 56.7743\n",
            "INFO:tensorflow:loss = 0.7697554, step = 4700 (1.762 sec)\n",
            "INFO:tensorflow:global_step/sec: 56.8725\n",
            "INFO:tensorflow:loss = 0.48181474, step = 4800 (1.758 sec)\n",
            "INFO:tensorflow:global_step/sec: 55.7361\n",
            "INFO:tensorflow:loss = 0.3071471, step = 4900 (1.794 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmpUyD8Tq/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-10-31-18:57:22\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpUyD8Tq/model.ckpt-5000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2018-10-31-18:57:25\n",
            "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.8413, average_loss = 0.46480885, global_step = 5000, loss = 0.46422938\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /tmp/tmpUyD8Tq/model.ckpt-5000\n",
            "INFO:tensorflow:Loss for final step: 0.6494812.\n",
            "Accuracy: 0.8413\n",
            "Loss: 0.46480885\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "a-1hE03c7_Yj"
      },
      "cell_type": "markdown",
      "source": [
        "The linear model with default parameters achieves about **84.13% accuracy**.\n",
        "\n",
        "Let's see if we can do better with the `simple_dnn` AdaNet:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "9fAoRYd19eUs",
        "outputId": "384b120c-0817-4cc2-cf03-e521960e1776",
        "colab": {
          "test": {
            "output": "ignore",
            "timeout": 900
          },
          "base_uri": "https://localhost:8080/",
          "height": 3403
        }
      },
      "cell_type": "code",
      "source": [
        "#@test {\"skip\": true}\n",
        "#@title Parameters\n",
        "LEARNING_RATE = 0.003  #@param {type:\"number\"}\n",
        "TRAIN_STEPS = 5000  #@param {type:\"integer\"}\n",
        "BATCH_SIZE = 64  #@param {type:\"integer\"}\n",
        "ADANET_ITERATIONS = 2  #@param {type:\"integer\"}\n",
        "\n",
        "estimator = adanet.Estimator(\n",
        "    head=head,\n",
        "    subnetwork_generator=Generator(\n",
        "        feature_columns=feature_columns,\n",
        "        optimizer=tf.train.RMSPropOptimizer(learning_rate=LEARNING_RATE),\n",
        "        seed=RANDOM_SEED),\n",
        "    max_iteration_steps=TRAIN_STEPS // ADANET_ITERATIONS,\n",
        "    evaluator=adanet.Evaluator(\n",
        "        input_fn=input_fn(\"train\", training=False, batch_size=BATCH_SIZE),\n",
        "        steps=None),\n",
        "    config=config)\n",
        "\n",
        "results, _ = tf.estimator.train_and_evaluate(\n",
        "    estimator,\n",
        "    train_spec=tf.estimator.TrainSpec(\n",
        "        input_fn=input_fn(\"train\", training=True, batch_size=BATCH_SIZE),\n",
        "        max_steps=TRAIN_STEPS),\n",
        "    eval_spec=tf.estimator.EvalSpec(\n",
        "        input_fn=input_fn(\"test\", training=False, batch_size=BATCH_SIZE),\n",
        "        steps=None))\n",
        "print(\"Accuracy:\", results[\"accuracy\"])\n",
        "print(\"Loss:\", results[\"average_loss\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpxIlcsR\n",
            "INFO:tensorflow:Using config: {'_save_checkpoints_secs': None, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f575b782f10>, '_model_dir': '/tmp/tmpxIlcsR', '_protocol': None, '_save_checkpoints_steps': 50000, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_tf_random_seed': 42, '_save_summary_steps': 50000, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_master': ''}\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 50000 or save_checkpoints_secs None.\n",
            "INFO:tensorflow:Beginning training AdaNet iteration 0\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpxIlcsR/model.ckpt.\n",
            "INFO:tensorflow:loss = 2.5908535, step = 0\n",
            "INFO:tensorflow:global_step/sec: 41.842\n",
            "INFO:tensorflow:loss = 0.9905158, step = 100 (2.392 sec)\n",
            "INFO:tensorflow:global_step/sec: 48.0856\n",
            "INFO:tensorflow:loss = 0.42087832, step = 200 (2.079 sec)\n",
            "INFO:tensorflow:global_step/sec: 47.8684\n",
            "INFO:tensorflow:loss = 0.54012996, step = 300 (2.089 sec)\n",
            "INFO:tensorflow:global_step/sec: 47.7846\n",
            "INFO:tensorflow:loss = 0.41349873, step = 400 (2.093 sec)\n",
            "INFO:tensorflow:global_step/sec: 47.1652\n",
            "INFO:tensorflow:loss = 0.56696236, step = 500 (2.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 48.1341\n",
            "INFO:tensorflow:loss = 0.39677918, step = 600 (2.077 sec)\n",
            "INFO:tensorflow:global_step/sec: 47.8733\n",
            "INFO:tensorflow:loss = 0.35278335, step = 700 (2.089 sec)\n",
            "INFO:tensorflow:global_step/sec: 48.1592\n",
            "INFO:tensorflow:loss = 0.5044695, step = 800 (2.076 sec)\n",
            "INFO:tensorflow:global_step/sec: 47.7272\n",
            "INFO:tensorflow:loss = 0.38145697, step = 900 (2.096 sec)\n",
            "INFO:tensorflow:global_step/sec: 47.5514\n",
            "INFO:tensorflow:loss = 0.20107023, step = 1000 (2.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 47.5665\n",
            "INFO:tensorflow:loss = 0.27366623, step = 1100 (2.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 47.8404\n",
            "INFO:tensorflow:loss = 0.42778075, step = 1200 (2.089 sec)\n",
            "INFO:tensorflow:global_step/sec: 47.6791\n",
            "INFO:tensorflow:loss = 0.38598642, step = 1300 (2.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 47.7096\n",
            "INFO:tensorflow:loss = 0.5578108, step = 1400 (2.096 sec)\n",
            "INFO:tensorflow:global_step/sec: 47.394\n",
            "INFO:tensorflow:loss = 0.4785679, step = 1500 (2.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 47.8889\n",
            "INFO:tensorflow:loss = 0.32456917, step = 1600 (2.088 sec)\n",
            "INFO:tensorflow:global_step/sec: 47.663\n",
            "INFO:tensorflow:loss = 0.14113681, step = 1700 (2.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 47.9615\n",
            "INFO:tensorflow:loss = 0.21314174, step = 1800 (2.085 sec)\n",
            "INFO:tensorflow:global_step/sec: 47.2946\n",
            "INFO:tensorflow:loss = 0.32758695, step = 1900 (2.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 46.6815\n",
            "INFO:tensorflow:loss = 0.335685, step = 2000 (2.143 sec)\n",
            "INFO:tensorflow:global_step/sec: 47.9355\n",
            "INFO:tensorflow:loss = 0.54023975, step = 2100 (2.086 sec)\n",
            "INFO:tensorflow:global_step/sec: 47.5537\n",
            "INFO:tensorflow:loss = 0.18559784, step = 2200 (2.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 47.2587\n",
            "INFO:tensorflow:loss = 0.63434565, step = 2300 (2.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 47.9377\n",
            "INFO:tensorflow:loss = 0.37059438, step = 2400 (2.086 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 2500 into /tmp/tmpxIlcsR/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-10-31-18:58:33\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpxIlcsR/model.ckpt-2500\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving candidate 'linear' dict for global step 2500: accuracy/adanet/adanet_weighted_ensemble = 0.8415, accuracy/adanet/subnetwork = 0.8415, accuracy/adanet/uniform_average_ensemble = 0.8415, architecture/adanet/ensembles = \n",
            "T\n",
            "6adanet/iteration_0/ensemble_linear/architecture/adanetB\u0010\b\u0007\u0012\u0000B\n",
            "| linear |J\b\n",
            "\u0006\n",
            "\u0004text, average_loss/adanet/adanet_weighted_ensemble = 0.48066866, average_loss/adanet/subnetwork = 0.48066866, average_loss/adanet/uniform_average_ensemble = 0.48066866, loss/adanet/adanet_weighted_ensemble = 0.47982836, loss/adanet/subnetwork = 0.47982836, loss/adanet/uniform_average_ensemble = 0.47982836\n",
            "INFO:tensorflow:Saving candidate '1_layer_dnn' dict for global step 2500: accuracy/adanet/adanet_weighted_ensemble = 0.8566, accuracy/adanet/subnetwork = 0.8566, accuracy/adanet/uniform_average_ensemble = 0.8566, architecture/adanet/ensembles = \n",
            "^\n",
            ";adanet/iteration_0/ensemble_1_layer_dnn/architecture/adanetB\u0015\b\u0007\u0012\u0000B\u000f| 1_layer_dnn |J\b\n",
            "\u0006\n",
            "\u0004text, average_loss/adanet/adanet_weighted_ensemble = 0.4086461, average_loss/adanet/subnetwork = 0.4086461, average_loss/adanet/uniform_average_ensemble = 0.4086461, loss/adanet/adanet_weighted_ensemble = 0.40789047, loss/adanet/subnetwork = 0.40789047, loss/adanet/uniform_average_ensemble = 0.40789047\n",
            "INFO:tensorflow:Finished evaluation at 2018-10-31-18:58:39\n",
            "INFO:tensorflow:Saving dict for global step 2500: accuracy = 0.8566, accuracy/adanet/adanet_weighted_ensemble = 0.8566, accuracy/adanet/subnetwork = 0.8566, accuracy/adanet/uniform_average_ensemble = 0.8566, average_loss = 0.4086461, average_loss/adanet/adanet_weighted_ensemble = 0.4086461, average_loss/adanet/subnetwork = 0.4086461, average_loss/adanet/uniform_average_ensemble = 0.4086461, global_step = 2500, loss = 0.40789047, loss/adanet/adanet_weighted_ensemble = 0.40789047, loss/adanet/subnetwork = 0.40789047, loss/adanet/uniform_average_ensemble = 0.40789047\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2500: /tmp/tmpxIlcsR/model.ckpt-2500\n",
            "INFO:tensorflow:Loss for final step: 0.34987575.\n",
            "INFO:tensorflow:Starting ensemble evaluation for iteration 0\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpxIlcsR/model.ckpt-2500\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/adanet/core/estimator.py:698: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:`tf.train.start_queue_runners()` was called when no queue runners were defined. You can safely remove the call to this deprecated function.\n",
            "INFO:tensorflow:Encountered end of input after 939 evaluations\n",
            "INFO:tensorflow:Computed ensemble metrics: adanet_loss/linear = 0.425563, adanet_loss/1_layer_dnn = 0.343846\n",
            "INFO:tensorflow:Finished ensemble evaluation for iteration 0\n",
            "INFO:tensorflow:'1_layer_dnn' at index 1 is moving onto the next iteration\n",
            "INFO:tensorflow:Freezing best ensemble to /tmp/tmpxIlcsR/frozen/ensemble-0.meta\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpxIlcsR/model.ckpt-2500\n",
            "INFO:tensorflow:Froze 5 variables.\n",
            "INFO:tensorflow:Converted 5 variables to const ops.\n",
            "INFO:tensorflow:Importing frozen ensemble from /tmp/tmpxIlcsR/frozen/ensemble-0.meta with features: ['images'].\n",
            "INFO:tensorflow:Overwriting checkpoint with new graph for iteration 1 to /tmp/tmpxIlcsR/model.ckpt-2500\n",
            "WARNING:tensorflow:`tf.train.start_queue_runners()` was called when no queue runners were defined. You can safely remove the call to this deprecated function.\n",
            "INFO:tensorflow:Finished training Adanet iteration 0\n",
            "INFO:tensorflow:Beginning training AdaNet iteration 1\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Importing frozen ensemble from /tmp/tmpxIlcsR/frozen/ensemble-0.meta with features: ['images'].\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpxIlcsR/increment.ckpt-1\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 2500 into /tmp/tmpxIlcsR/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.24298608, step = 2500\n",
            "INFO:tensorflow:global_step/sec: 36.8425\n",
            "INFO:tensorflow:loss = 0.33409065, step = 2600 (2.715 sec)\n",
            "INFO:tensorflow:global_step/sec: 43.8269\n",
            "INFO:tensorflow:loss = 0.20756067, step = 2700 (2.282 sec)\n",
            "INFO:tensorflow:global_step/sec: 43.6816\n",
            "INFO:tensorflow:loss = 0.34230402, step = 2800 (2.289 sec)\n",
            "INFO:tensorflow:global_step/sec: 43.5056\n",
            "INFO:tensorflow:loss = 0.38019758, step = 2900 (2.299 sec)\n",
            "INFO:tensorflow:global_step/sec: 43.336\n",
            "INFO:tensorflow:loss = 0.31078094, step = 3000 (2.307 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.0605\n",
            "INFO:tensorflow:loss = 0.2353633, step = 3100 (2.270 sec)\n",
            "INFO:tensorflow:global_step/sec: 43.7516\n",
            "INFO:tensorflow:loss = 0.2586084, step = 3200 (2.286 sec)\n",
            "INFO:tensorflow:global_step/sec: 43.938\n",
            "INFO:tensorflow:loss = 0.37581128, step = 3300 (2.276 sec)\n",
            "INFO:tensorflow:global_step/sec: 42.8484\n",
            "INFO:tensorflow:loss = 0.2537661, step = 3400 (2.334 sec)\n",
            "INFO:tensorflow:global_step/sec: 43.3714\n",
            "INFO:tensorflow:loss = 0.14187168, step = 3500 (2.305 sec)\n",
            "INFO:tensorflow:global_step/sec: 43.7854\n",
            "INFO:tensorflow:loss = 0.2681305, step = 3600 (2.284 sec)\n",
            "INFO:tensorflow:global_step/sec: 43.3243\n",
            "INFO:tensorflow:loss = 0.40180224, step = 3700 (2.308 sec)\n",
            "INFO:tensorflow:global_step/sec: 43.056\n",
            "INFO:tensorflow:loss = 0.32000825, step = 3800 (2.323 sec)\n",
            "INFO:tensorflow:global_step/sec: 43.6017\n",
            "INFO:tensorflow:loss = 0.36946106, step = 3900 (2.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 43.7591\n",
            "INFO:tensorflow:loss = 0.38832635, step = 4000 (2.285 sec)\n",
            "INFO:tensorflow:global_step/sec: 43.8507\n",
            "INFO:tensorflow:loss = 0.34555006, step = 4100 (2.280 sec)\n",
            "INFO:tensorflow:global_step/sec: 43.9355\n",
            "INFO:tensorflow:loss = 0.18096374, step = 4200 (2.276 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.212\n",
            "INFO:tensorflow:loss = 0.19382226, step = 4300 (2.262 sec)\n",
            "INFO:tensorflow:global_step/sec: 43.7453\n",
            "INFO:tensorflow:loss = 0.33417186, step = 4400 (2.286 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.2697\n",
            "INFO:tensorflow:loss = 0.35368264, step = 4500 (2.259 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.5295\n",
            "INFO:tensorflow:loss = 0.51710737, step = 4600 (2.246 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.0157\n",
            "INFO:tensorflow:loss = 0.18360963, step = 4700 (2.272 sec)\n",
            "INFO:tensorflow:global_step/sec: 44.0691\n",
            "INFO:tensorflow:loss = 0.50974315, step = 4800 (2.269 sec)\n",
            "INFO:tensorflow:global_step/sec: 43.9336\n",
            "INFO:tensorflow:loss = 0.2954695, step = 4900 (2.276 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmpxIlcsR/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Importing frozen ensemble from /tmp/tmpxIlcsR/frozen/ensemble-0.meta with features: ['images'].\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-10-31-19:00:06\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpxIlcsR/model.ckpt-5000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving candidate 'previous_ensemble' dict for global step 5000: accuracy/adanet/adanet_weighted_ensemble = 0.8566, accuracy/adanet/subnetwork = 0.8566, accuracy/adanet/uniform_average_ensemble = 0.8566, architecture/adanet/ensembles = \n",
            "O\n",
            ",adanet/previous_ensemble/architecture/adanetB\u0015\b\u0007\u0012\u0000B\u000f| 1_layer_dnn |J\b\n",
            "\u0006\n",
            "\u0004text, average_loss/adanet/adanet_weighted_ensemble = 0.4086461, average_loss/adanet/subnetwork = 0.4086461, average_loss/adanet/uniform_average_ensemble = 0.4086461, loss/adanet/adanet_weighted_ensemble = 0.40789047, loss/adanet/subnetwork = 0.40789047, loss/adanet/uniform_average_ensemble = 0.40789047\n",
            "INFO:tensorflow:Saving candidate '1_layer_dnn' dict for global step 5000: accuracy/adanet/adanet_weighted_ensemble = 0.8619, accuracy/adanet/subnetwork = 0.8554, accuracy/adanet/uniform_average_ensemble = 0.8619, architecture/adanet/ensembles = \n",
            "l\n",
            ";adanet/iteration_1/ensemble_1_layer_dnn/architecture/adanetB#\b\u0007\u0012\u0000B\u001d| 1_layer_dnn | 1_layer_dnn |J\b\n",
            "\u0006\n",
            "\u0004text, average_loss/adanet/adanet_weighted_ensemble = 0.38650024, average_loss/adanet/subnetwork = 0.41150853, average_loss/adanet/uniform_average_ensemble = 0.38650024, loss/adanet/adanet_weighted_ensemble = 0.3857878, loss/adanet/subnetwork = 0.4108744, loss/adanet/uniform_average_ensemble = 0.3857878\n",
            "INFO:tensorflow:Saving candidate '2_layer_dnn' dict for global step 5000: accuracy/adanet/adanet_weighted_ensemble = 0.8614, accuracy/adanet/subnetwork = 0.8531, accuracy/adanet/uniform_average_ensemble = 0.8614, architecture/adanet/ensembles = \n",
            "l\n",
            ";adanet/iteration_1/ensemble_2_layer_dnn/architecture/adanetB#\b\u0007\u0012\u0000B\u001d| 1_layer_dnn | 2_layer_dnn |J\b\n",
            "\u0006\n",
            "\u0004text, average_loss/adanet/adanet_weighted_ensemble = 0.3910556, average_loss/adanet/subnetwork = 0.42163697, average_loss/adanet/uniform_average_ensemble = 0.3910556, loss/adanet/adanet_weighted_ensemble = 0.39028054, loss/adanet/subnetwork = 0.420988, loss/adanet/uniform_average_ensemble = 0.39028054\n",
            "INFO:tensorflow:Finished evaluation at 2018-10-31-19:00:13\n",
            "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.8566, accuracy/adanet/adanet_weighted_ensemble = 0.8566, accuracy/adanet/subnetwork = 0.8566, accuracy/adanet/uniform_average_ensemble = 0.8566, average_loss = 0.4086461, average_loss/adanet/adanet_weighted_ensemble = 0.4086461, average_loss/adanet/subnetwork = 0.4086461, average_loss/adanet/uniform_average_ensemble = 0.4086461, global_step = 5000, loss = 0.40789047, loss/adanet/adanet_weighted_ensemble = 0.40789047, loss/adanet/subnetwork = 0.40789047, loss/adanet/uniform_average_ensemble = 0.40789047\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /tmp/tmpxIlcsR/model.ckpt-5000\n",
            "INFO:tensorflow:Loss for final step: 0.21913758.\n",
            "Accuracy: 0.8566\n",
            "Loss: 0.4086461\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ysWsJ3zXDwNx"
      },
      "cell_type": "markdown",
      "source": [
        "The `simple_dnn` AdaNet model with default parameters achieves about **85.66%\n",
        "accuracy**.\n",
        "\n",
        "This improvement can be attributed to `simple_dnn` searching over\n",
        "fully-connected neural networks which have more expressive power than the linear\n",
        "model due to their non-linear activations.\n",
        "\n",
        "Fully-connected layers are permutation invariant to their inputs, meaning that\n",
        "if we consistently swapped two pixels before training, the final model would\n",
        "perform identically. However, there is spatial and locality information in\n",
        "images that we should try to capture. Applying a few convolutions to our inputs\n",
        "will allow us to do so, and that will require defining a custom\n",
        "`adanet.subnetwork.Builder` and `adanet.subnetwork.Generator`."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "D3IE6-9vFVlg"
      },
      "cell_type": "markdown",
      "source": [
        "## Define a convolutional AdaNet model\n",
        "\n",
        "Creating a new search space for AdaNet to explore is straightforward. There are\n",
        "two abstract classes you need to extend:\n",
        "\n",
        "1.  `adanet.subnetwork.Builder`\n",
        "2.  `adanet.subnetwork.Generator`\n",
        "\n",
        "Similar to the tf.estimator.Estimator `model_fn`, `adanet.subnetwork.Builder`\n",
        "allows you to define your own TensorFlow graph for creating a neural network,\n",
        "and specify the training operations.\n",
        "\n",
        "Below we define one that applies a 2D convolution, max-pooling, and then a\n",
        "fully-connected layer to the images:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "IsYJ97tRwBkt",
        "colab": {
          "test": {
            "output": "ignore",
            "timeout": 900
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class SimpleCNNBuilder(adanet.subnetwork.Builder):\n",
        "  \"\"\"Builds a CNN subnetwork for AdaNet.\"\"\"\n",
        "\n",
        "  def __init__(self, learning_rate, max_iteration_steps, seed):\n",
        "    \"\"\"Initializes a `SimpleCNNBuilder`.\n",
        "\n",
        "    Args:\n",
        "      learning_rate: The float learning rate to use.\n",
        "      max_iteration_steps: The number of steps per iteration.\n",
        "      seed: The random seed.\n",
        "\n",
        "    Returns:\n",
        "      An instance of `SimpleCNNBuilder`.\n",
        "    \"\"\"\n",
        "    self._learning_rate = learning_rate\n",
        "    self._max_iteration_steps = max_iteration_steps\n",
        "    self._seed = seed\n",
        "\n",
        "  def build_subnetwork(self,\n",
        "                       features,\n",
        "                       logits_dimension,\n",
        "                       training,\n",
        "                       iteration_step,\n",
        "                       summary,\n",
        "                       previous_ensemble=None):\n",
        "    \"\"\"See `adanet.subnetwork.Builder`.\"\"\"\n",
        "    images = features.values()[0]\n",
        "    kernel_initializer = tf.keras.initializers.he_normal(seed=self._seed)\n",
        "    x = tf.layers.conv2d(\n",
        "        images,\n",
        "        filters=16,\n",
        "        kernel_size=3,\n",
        "        padding=\"same\",\n",
        "        activation=\"relu\",\n",
        "        kernel_initializer=kernel_initializer)\n",
        "    x = tf.layers.max_pooling2d(x, pool_size=2, strides=2)\n",
        "    x = tf.layers.flatten(x)\n",
        "    x = tf.layers.dense(\n",
        "        x, units=64, activation=\"relu\", kernel_initializer=kernel_initializer)\n",
        "\n",
        "    # The `Head` passed to adanet.Estimator will apply the softmax activation.\n",
        "    logits = tf.layers.dense(\n",
        "        x, units=10, activation=None, kernel_initializer=kernel_initializer)\n",
        "\n",
        "    # Use a constant complexity measure, since all subnetworks have the same\n",
        "    # architecture and hyperparameters.\n",
        "    complexity = tf.constant(1)\n",
        "\n",
        "    return adanet.Subnetwork(\n",
        "        last_layer=x,\n",
        "        logits=logits,\n",
        "        complexity=complexity,\n",
        "        persisted_tensors={})\n",
        "\n",
        "  def build_subnetwork_train_op(self, \n",
        "                                subnetwork, \n",
        "                                loss, \n",
        "                                var_list, \n",
        "                                labels, \n",
        "                                iteration_step,\n",
        "                                summary, \n",
        "                                previous_ensemble=None):\n",
        "    \"\"\"See `adanet.subnetwork.Builder`.\"\"\"\n",
        "\n",
        "    # Momentum optimizer with cosine learning rate decay works well with CNNs.\n",
        "    learning_rate = tf.train.cosine_decay(\n",
        "        learning_rate=self._learning_rate,\n",
        "        global_step=iteration_step,\n",
        "        decay_steps=self._max_iteration_steps)\n",
        "    optimizer = tf.train.MomentumOptimizer(learning_rate, .9)\n",
        "    # NOTE: The `adanet.Estimator` increments the global step.\n",
        "    return optimizer.minimize(loss=loss, var_list=var_list)\n",
        "\n",
        "  def build_mixture_weights_train_op(self, loss, var_list, logits, labels,\n",
        "                                     iteration_step, summary):\n",
        "    \"\"\"See `adanet.subnetwork.Builder`.\"\"\"\n",
        "    return tf.no_op(\"mixture_weights_train_op\")\n",
        "\n",
        "  @property\n",
        "  def name(self):\n",
        "    \"\"\"See `adanet.subnetwork.Builder`.\"\"\"\n",
        "    return \"simple_cnn\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "OFamPrZHJ5ii"
      },
      "cell_type": "markdown",
      "source": [
        "Next, we extend a `adanet.subnetwork.Generator`, which defines the search\n",
        "space of candidate `SimpleCNNBuilders` to consider including the final network.\n",
        "It can create one or more at each iteration with different parameters, and the\n",
        "AdaNet algorithm will select the candidate that best improves the overall neural\n",
        "network's `adanet_loss` on the training set.\n",
        "\n",
        "The one below is very simple: it always creates the same architecture, but gives\n",
        "it a different random seed at each iteration:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-BAnb_XGwhRy",
        "colab": {
          "test": {
            "output": "ignore",
            "timeout": 900
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class SimpleCNNGenerator(adanet.subnetwork.Generator):\n",
        "  \"\"\"Generates a `SimpleCNN` at each iteration.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, learning_rate, max_iteration_steps, seed=None):\n",
        "    \"\"\"Initializes a `Generator` that builds `SimpleCNNs`.\n",
        "\n",
        "    Args:\n",
        "      learning_rate: The float learning rate to use.\n",
        "      max_iteration_steps: The number of steps per iteration.\n",
        "      seed: The random seed.\n",
        "\n",
        "    Returns:\n",
        "      An instance of `Generator`.\n",
        "    \"\"\"\n",
        "    self._seed = seed\n",
        "    self._dnn_builder_fn = functools.partial(\n",
        "        SimpleCNNBuilder,\n",
        "        learning_rate=learning_rate,\n",
        "        max_iteration_steps=max_iteration_steps)\n",
        "\n",
        "  def generate_candidates(self, previous_ensemble, iteration_number,\n",
        "                          previous_ensemble_reports, all_reports):\n",
        "    \"\"\"See `adanet.subnetwork.Generator`.\"\"\"\n",
        "    seed = self._seed\n",
        "    # Change the seed according to the iteration so that each subnetwork\n",
        "    # learns something different.\n",
        "    if seed is not None:\n",
        "      seed += iteration_number\n",
        "    return [self._dnn_builder_fn(seed=seed)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "8sdvharsLJ1T"
      },
      "cell_type": "markdown",
      "source": [
        "With these defined, we pass them into a new `adanet.Estimator`:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-Fhi1SjkzVBt",
        "outputId": "82fcb4ed-87c5-4d1c-a434-52d73d1f3664",
        "colab": {
          "test": {
            "output": "ignore",
            "timeout": 900
          },
          "base_uri": "https://localhost:8080/",
          "height": 3182
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Parameters\n",
        "LEARNING_RATE = 0.05  #@param {type:\"number\"}\n",
        "TRAIN_STEPS = 5000  #@param {type:\"integer\"}\n",
        "BATCH_SIZE = 64  #@param {type:\"integer\"}\n",
        "ADANET_ITERATIONS = 2  #@param {type:\"integer\"}\n",
        "\n",
        "max_iteration_steps = TRAIN_STEPS // ADANET_ITERATIONS\n",
        "estimator = adanet.Estimator(\n",
        "    head=head,\n",
        "    subnetwork_generator=SimpleCNNGenerator(\n",
        "        learning_rate=LEARNING_RATE,\n",
        "        max_iteration_steps=max_iteration_steps,\n",
        "        seed=RANDOM_SEED),\n",
        "    max_iteration_steps=max_iteration_steps,\n",
        "    evaluator=adanet.Evaluator(\n",
        "        input_fn=input_fn(\"train\", training=False, batch_size=BATCH_SIZE),\n",
        "        steps=None),\n",
        "    report_materializer=adanet.ReportMaterializer(\n",
        "        input_fn=input_fn(\"train\", training=False, batch_size=BATCH_SIZE),\n",
        "        steps=None),\n",
        "    adanet_loss_decay=.99,\n",
        "    config=config)\n",
        "\n",
        "results, _ = tf.estimator.train_and_evaluate(\n",
        "    estimator,\n",
        "    train_spec=tf.estimator.TrainSpec(\n",
        "        input_fn=input_fn(\"train\", training=True, batch_size=BATCH_SIZE),\n",
        "        max_steps=TRAIN_STEPS),\n",
        "    eval_spec=tf.estimator.EvalSpec(\n",
        "        input_fn=input_fn(\"test\", training=False, batch_size=BATCH_SIZE),\n",
        "        steps=None))\n",
        "print(\"Accuracy:\", results[\"accuracy\"])\n",
        "print(\"Loss:\", results[\"average_loss\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp1jRUwL\n",
            "INFO:tensorflow:Using config: {'_save_checkpoints_secs': None, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5752118d90>, '_model_dir': '/tmp/tmp1jRUwL', '_protocol': None, '_save_checkpoints_steps': 50000, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_tf_random_seed': 42, '_save_summary_steps': 50000, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_master': ''}\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 50000 or save_checkpoints_secs None.\n",
            "INFO:tensorflow:Beginning training AdaNet iteration 0\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp1jRUwL/model.ckpt.\n",
            "INFO:tensorflow:loss = 2.694181, step = 0\n",
            "INFO:tensorflow:global_step/sec: 44.2519\n",
            "INFO:tensorflow:loss = 0.46705627, step = 100 (2.261 sec)\n",
            "INFO:tensorflow:global_step/sec: 49.8253\n",
            "INFO:tensorflow:loss = 0.2509607, step = 200 (2.007 sec)\n",
            "INFO:tensorflow:global_step/sec: 49.1586\n",
            "INFO:tensorflow:loss = 0.33263743, step = 300 (2.035 sec)\n",
            "INFO:tensorflow:global_step/sec: 49.3728\n",
            "INFO:tensorflow:loss = 0.32466513, step = 400 (2.025 sec)\n",
            "INFO:tensorflow:global_step/sec: 49.6382\n",
            "INFO:tensorflow:loss = 0.34593388, step = 500 (2.015 sec)\n",
            "INFO:tensorflow:global_step/sec: 50.3158\n",
            "INFO:tensorflow:loss = 0.1477409, step = 600 (1.987 sec)\n",
            "INFO:tensorflow:global_step/sec: 49.7516\n",
            "INFO:tensorflow:loss = 0.3962487, step = 700 (2.010 sec)\n",
            "INFO:tensorflow:global_step/sec: 49.8224\n",
            "INFO:tensorflow:loss = 0.38936856, step = 800 (2.007 sec)\n",
            "INFO:tensorflow:global_step/sec: 49.1603\n",
            "INFO:tensorflow:loss = 0.19988975, step = 900 (2.034 sec)\n",
            "INFO:tensorflow:global_step/sec: 49.1853\n",
            "INFO:tensorflow:loss = 0.16779959, step = 1000 (2.033 sec)\n",
            "INFO:tensorflow:global_step/sec: 49.0013\n",
            "INFO:tensorflow:loss = 0.15724452, step = 1100 (2.041 sec)\n",
            "INFO:tensorflow:global_step/sec: 49.0226\n",
            "INFO:tensorflow:loss = 0.29659802, step = 1200 (2.040 sec)\n",
            "INFO:tensorflow:global_step/sec: 47.0793\n",
            "INFO:tensorflow:loss = 0.25753057, step = 1300 (2.124 sec)\n",
            "INFO:tensorflow:global_step/sec: 47.0803\n",
            "INFO:tensorflow:loss = 0.23135924, step = 1400 (2.124 sec)\n",
            "INFO:tensorflow:global_step/sec: 47.4833\n",
            "INFO:tensorflow:loss = 0.27126792, step = 1500 (2.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 47.4417\n",
            "INFO:tensorflow:loss = 0.21830234, step = 1600 (2.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 46.7483\n",
            "INFO:tensorflow:loss = 0.104334526, step = 1700 (2.139 sec)\n",
            "INFO:tensorflow:global_step/sec: 46.5634\n",
            "INFO:tensorflow:loss = 0.13090102, step = 1800 (2.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 46.4203\n",
            "INFO:tensorflow:loss = 0.14267835, step = 1900 (2.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 47.8691\n",
            "INFO:tensorflow:loss = 0.22857067, step = 2000 (2.089 sec)\n",
            "INFO:tensorflow:global_step/sec: 48.7445\n",
            "INFO:tensorflow:loss = 0.17645808, step = 2100 (2.052 sec)\n",
            "INFO:tensorflow:global_step/sec: 49.1529\n",
            "INFO:tensorflow:loss = 0.1356284, step = 2200 (2.034 sec)\n",
            "INFO:tensorflow:global_step/sec: 49.4213\n",
            "INFO:tensorflow:loss = 0.40205738, step = 2300 (2.023 sec)\n",
            "INFO:tensorflow:global_step/sec: 48.8808\n",
            "INFO:tensorflow:loss = 0.11778937, step = 2400 (2.046 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 2500 into /tmp/tmp1jRUwL/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-10-31-19:02:56\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp1jRUwL/model.ckpt-2500\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving candidate 'simple_cnn' dict for global step 2500: accuracy/adanet/adanet_weighted_ensemble = 0.9013, accuracy/adanet/subnetwork = 0.9013, accuracy/adanet/uniform_average_ensemble = 0.9013, architecture/adanet/ensembles = \n",
            "\\\n",
            ":adanet/iteration_0/ensemble_simple_cnn/architecture/adanetB\u0014\b\u0007\u0012\u0000B\u000e| simple_cnn |J\b\n",
            "\u0006\n",
            "\u0004text, average_loss/adanet/adanet_weighted_ensemble = 0.2722113, average_loss/adanet/subnetwork = 0.2722113, average_loss/adanet/uniform_average_ensemble = 0.2722113, loss/adanet/adanet_weighted_ensemble = 0.27218473, loss/adanet/subnetwork = 0.27218473, loss/adanet/uniform_average_ensemble = 0.27218473\n",
            "INFO:tensorflow:Finished evaluation at 2018-10-31-19:03:01\n",
            "INFO:tensorflow:Saving dict for global step 2500: accuracy = 0.9013, accuracy/adanet/adanet_weighted_ensemble = 0.9013, accuracy/adanet/subnetwork = 0.9013, accuracy/adanet/uniform_average_ensemble = 0.9013, average_loss = 0.2722113, average_loss/adanet/adanet_weighted_ensemble = 0.2722113, average_loss/adanet/subnetwork = 0.2722113, average_loss/adanet/uniform_average_ensemble = 0.2722113, global_step = 2500, loss = 0.27218473, loss/adanet/adanet_weighted_ensemble = 0.27218473, loss/adanet/subnetwork = 0.27218473, loss/adanet/uniform_average_ensemble = 0.27218473\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2500: /tmp/tmp1jRUwL/model.ckpt-2500\n",
            "INFO:tensorflow:Loss for final step: 0.2628069.\n",
            "INFO:tensorflow:As the only candidate, 'simple_cnn' is moving onto the next iteration.\n",
            "INFO:tensorflow:Starting metric logging for iteration 0\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp1jRUwL/model.ckpt-2500\n",
            "WARNING:tensorflow:`tf.train.start_queue_runners()` was called when no queue runners were defined. You can safely remove the call to this deprecated function.\n",
            "INFO:tensorflow:Encountered end of input during report materialization\n",
            "INFO:tensorflow:Materialized subnetwork_reports.\n",
            "INFO:tensorflow:Wrote IterationReport for iteration 0 to /tmp/tmp1jRUwL/report/iteration_reports.tfrecord\n",
            "INFO:tensorflow:Finished saving subnetwork reports for iteration 0\n",
            "INFO:tensorflow:Freezing best ensemble to /tmp/tmp1jRUwL/frozen/ensemble-0.meta\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp1jRUwL/model.ckpt-2500\n",
            "INFO:tensorflow:Froze 7 variables.\n",
            "INFO:tensorflow:Converted 7 variables to const ops.\n",
            "INFO:tensorflow:Importing frozen ensemble from /tmp/tmp1jRUwL/frozen/ensemble-0.meta with features: ['images'].\n",
            "INFO:tensorflow:Overwriting checkpoint with new graph for iteration 1 to /tmp/tmp1jRUwL/model.ckpt-2500\n",
            "WARNING:tensorflow:`tf.train.start_queue_runners()` was called when no queue runners were defined. You can safely remove the call to this deprecated function.\n",
            "INFO:tensorflow:Finished training Adanet iteration 0\n",
            "INFO:tensorflow:Beginning training AdaNet iteration 1\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Importing frozen ensemble from /tmp/tmp1jRUwL/frozen/ensemble-0.meta with features: ['images'].\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp1jRUwL/increment.ckpt-1\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 2500 into /tmp/tmp1jRUwL/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.16295284, step = 2500\n",
            "INFO:tensorflow:global_step/sec: 39.8641\n",
            "INFO:tensorflow:loss = 0.19952151, step = 2600 (2.510 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.6869\n",
            "INFO:tensorflow:loss = 0.09160632, step = 2700 (2.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.6742\n",
            "INFO:tensorflow:loss = 0.2302818, step = 2800 (2.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.7472\n",
            "INFO:tensorflow:loss = 0.31564337, step = 2900 (2.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.396\n",
            "INFO:tensorflow:loss = 0.13141912, step = 3000 (2.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.2457\n",
            "INFO:tensorflow:loss = 0.07869934, step = 3100 (2.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.6927\n",
            "INFO:tensorflow:loss = 0.2544695, step = 3200 (2.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.8374\n",
            "INFO:tensorflow:loss = 0.28264976, step = 3300 (2.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 46.0223\n",
            "INFO:tensorflow:loss = 0.13375653, step = 3400 (2.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.9536\n",
            "INFO:tensorflow:loss = 0.10732888, step = 3500 (2.176 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.9304\n",
            "INFO:tensorflow:loss = 0.07423252, step = 3600 (2.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 46.1941\n",
            "INFO:tensorflow:loss = 0.19244727, step = 3700 (2.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.7064\n",
            "INFO:tensorflow:loss = 0.21358019, step = 3800 (2.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.7554\n",
            "INFO:tensorflow:loss = 0.2045016, step = 3900 (2.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.5783\n",
            "INFO:tensorflow:loss = 0.18400535, step = 4000 (2.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.5082\n",
            "INFO:tensorflow:loss = 0.18395306, step = 4100 (2.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 46.1335\n",
            "INFO:tensorflow:loss = 0.08272165, step = 4200 (2.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.1018\n",
            "INFO:tensorflow:loss = 0.108557306, step = 4300 (2.217 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.1788\n",
            "INFO:tensorflow:loss = 0.13537517, step = 4400 (2.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.0216\n",
            "INFO:tensorflow:loss = 0.21809316, step = 4500 (2.221 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.9463\n",
            "INFO:tensorflow:loss = 0.1696476, step = 4600 (2.176 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.4767\n",
            "INFO:tensorflow:loss = 0.13441238, step = 4700 (2.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 46.1347\n",
            "INFO:tensorflow:loss = 0.35789576, step = 4800 (2.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 45.9611\n",
            "INFO:tensorflow:loss = 0.11466265, step = 4900 (2.176 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmp1jRUwL/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Importing frozen ensemble from /tmp/tmp1jRUwL/frozen/ensemble-0.meta with features: ['images'].\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-10-31-19:04:25\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp1jRUwL/model.ckpt-5000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving candidate 'previous_ensemble' dict for global step 5000: accuracy/adanet/adanet_weighted_ensemble = 0.9013, accuracy/adanet/subnetwork = 0.9013, accuracy/adanet/uniform_average_ensemble = 0.9013, architecture/adanet/ensembles = \n",
            "N\n",
            ",adanet/previous_ensemble/architecture/adanetB\u0014\b\u0007\u0012\u0000B\u000e| simple_cnn |J\b\n",
            "\u0006\n",
            "\u0004text, average_loss/adanet/adanet_weighted_ensemble = 0.2722113, average_loss/adanet/subnetwork = 0.2722113, average_loss/adanet/uniform_average_ensemble = 0.2722113, loss/adanet/adanet_weighted_ensemble = 0.27218473, loss/adanet/subnetwork = 0.27218473, loss/adanet/uniform_average_ensemble = 0.27218473\n",
            "INFO:tensorflow:Saving candidate 'simple_cnn' dict for global step 5000: accuracy/adanet/adanet_weighted_ensemble = 0.903, accuracy/adanet/subnetwork = 0.9009, accuracy/adanet/uniform_average_ensemble = 0.903, architecture/adanet/ensembles = \n",
            "i\n",
            ":adanet/iteration_1/ensemble_simple_cnn/architecture/adanetB!\b\u0007\u0012\u0000B\u001b| simple_cnn | simple_cnn |J\b\n",
            "\u0006\n",
            "\u0004text, average_loss/adanet/adanet_weighted_ensemble = 0.26386255, average_loss/adanet/subnetwork = 0.27632794, average_loss/adanet/uniform_average_ensemble = 0.26386255, loss/adanet/adanet_weighted_ensemble = 0.26377663, loss/adanet/subnetwork = 0.27620167, loss/adanet/uniform_average_ensemble = 0.26377663\n",
            "INFO:tensorflow:Finished evaluation at 2018-10-31-19:04:30\n",
            "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.903, accuracy/adanet/adanet_weighted_ensemble = 0.903, accuracy/adanet/subnetwork = 0.9009, accuracy/adanet/uniform_average_ensemble = 0.903, average_loss = 0.26386255, average_loss/adanet/adanet_weighted_ensemble = 0.26386255, average_loss/adanet/subnetwork = 0.27632794, average_loss/adanet/uniform_average_ensemble = 0.26386255, global_step = 5000, loss = 0.26377663, loss/adanet/adanet_weighted_ensemble = 0.26377663, loss/adanet/subnetwork = 0.27620167, loss/adanet/uniform_average_ensemble = 0.26377663\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /tmp/tmp1jRUwL/model.ckpt-5000\n",
            "INFO:tensorflow:Loss for final step: 0.24161696.\n",
            "Accuracy: 0.903\n",
            "Loss: 0.26386255\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "3wGtI-4_LRw1"
      },
      "cell_type": "markdown",
      "source": [
        "Our `SimpleCNNGenerator` code achieves **90.41% accuracy**."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "TKhCzP65hGyS"
      },
      "cell_type": "markdown",
      "source": [
        "## Conclusion and next steps\n",
        "\n",
        "In this tutorial, you learned how to customize `adanet` to encode your\n",
        "understanding of a particular dataset, and explore novel search spaces with\n",
        "AdaNet.\n",
        "\n",
        "One use-case that has worked for us at Google, has been to take a production\n",
        "model's TensorFlow code, convert it to into an `adanet.subnetwork.Builder`, and\n",
        "adaptively grow it into an ensemble. In many cases, this has given significant\n",
        "performance improvements.\n",
        "\n",
        "As an exercise, you can swap out the FASHION-MNIST with the MNIST handwritten\n",
        "digits dataset in this notebook using `tf.keras.datasets.mnist.load_data()`, and\n",
        "see how `SimpleCNN` performs."
      ]
    }
  ]
}